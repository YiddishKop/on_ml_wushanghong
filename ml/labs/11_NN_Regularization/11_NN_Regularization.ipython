from IPython.display import Image
from IPython.display import display

# inline plotting instead of popping out
%matplotlib inline

# load utility classes/functions that has been taught in previous labs
# e.g., plot_decision_regions()
import os, sys
module_path = os.path.abspath(os.path.join('.'))
sys.path.append(module_path)
from lib import *

from keras.datasets import cifar10
from keras.utils import np_utils

(X_train, y_train), (X_test, y_test) = cifar10.load_data()

# convert class vectors to binary vectors
Y_train = np_utils.to_categorical(y_train)
Y_test = np_utils.to_categorical(y_test)

print('X_train shape:', X_train.shape)
print('Y_train shape:', Y_train.shape)
print('X_test shape:', X_test.shape)
print('Y_test shape:', Y_test.shape)

X_train shape: (50000, 32, 32, 3)
Y_train shape: (50000, 10)
X_test shape: (10000, 32, 32, 3)
Y_test shape: (10000, 10)

# dataset path
home = os.path.expanduser('~')
data_path = os.path.join(home, "data/CIFAR-10/")
data_url = "https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"

# CIFAR-10 constants
img_size = 32
img_channels = 3
nb_classes = 10
# length of the image after we flatten the image into a 1-D array
img_size_flat = img_size * img_size * img_channels
nb_files_train = 5
images_per_file = 10000
# number of all the images in the training dataset
nb_images_train = nb_files_train * images_per_file

import urllib.request
import tarfile

def download_and_extract_cifar():
    if not os.path.exists(data_path):
        os.makedirs(data_path)

        file_path, _ = urllib.request.urlretrieve(url=data_url,
                                                  filename=os.path.join(data_path, 'cifar-10-python.tar.gz'),
                                                  reporthook=print_download_progress)
        print('\nExtracting... ', end='')
        tarfile.open(name=file_path, mode="r:gz").extractall(data_path)
        print('done')
    else:
        print("Data has already been downloaded and unpacked.")

download_and_extract_cifar()

Data has already been downloaded and unpacked.

import _pickle as pickle
from keras.utils import np_utils
import numpy as np

def load_data(file_name):
    file_path = os.path.join(data_path, "cifar-10-batches-py/", file_name)

    print('Loading ' + file_name)
    with open(file_path, mode='rb') as file:    
        data = pickle.load(file, encoding='bytes')
    raw_images = data[b'data']
    cls = np.array(data[b'labels'])

    images = raw_images.reshape([-1, img_channels, img_size, img_size])    
    # move the channel dimension to the last
    images = np.rollaxis(images, 1, 4)

    return images, cls

def load_training_data():    
    # pre-allocate the arrays for the images and class-numbers for efficiency.
    images = np.zeros(shape=[nb_images_train, img_size, img_size, img_channels], 
                      dtype=int)
    cls = np.zeros(shape=[nb_images_train], dtype=int)

    begin = 0
    for i in range(nb_files_train):
        images_batch, cls_batch = load_data(file_name="data_batch_" + str(i + 1))
        num_images = len(images_batch)
        end = begin + num_images
        images[begin:end, :] = images_batch
        cls[begin:end] = cls_batch
        begin = end

    return images, np_utils.to_categorical(cls, nb_classes)

def load_test_data():
    images, cls = load_data(file_name="test_batch")

    return images, np_utils.to_categorical(cls, nb_classes)

def load_cifar():
    X_train, Y_train = load_training_data()
    X_test, Y_test = load_test_data()

    return X_train, Y_train, X_test, Y_test

X_train, Y_train, X_test, Y_test = load_cifar()

print('\nX_train shape:', X_train.shape)
print('Y_train shape:', Y_train.shape)
print('X_test shape:', X_test.shape)
print('Y_test shape:', Y_test.shape)

Loading data_batch_1
Loading data_batch_2
Loading data_batch_3
Loading data_batch_4
Loading data_batch_5
Loading test_batch

X_train shape: (50000, 32, 32, 3)
Y_train shape: (50000, 10)
X_test shape: (10000, 32, 32, 3)
Y_test shape: (10000, 10)

# normalize inputs from 0-255 to 0.0-1.0
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train = X_train / 255.0
X_test = X_test / 255.0

import matplotlib.pyplot as plt

def grayscale(data, dtype='float32'):
    # luma coding weighted average in video systems
    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)
    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]
    # add channel dimension
    rst = np.expand_dims(rst, axis=3)
    return rst

X_train_gray = grayscale(X_train)
X_test_gray = grayscale(X_test)

# now we have only one channel in the images
img_channels = 1

# plot a randomly chosen image
img = 64
plt.figure(figsize=(4, 2))
plt.subplot(1, 2, 1)
plt.imshow(X_train[img], interpolation='none')
plt.subplot(1, 2, 2)
plt.imshow(X_train_gray[img, :, :, 0], cmap=plt.get_cmap('gray'), interpolation='none')
plt.show()

from sklearn.model_selection import train_test_split

X_train_gray, X_val_gray, Y_train, Y_val = train_test_split(X_train_gray, Y_train, test_size=0.2, random_state=0)

print('X_train_gray shape:', X_train_gray.shape)
print('X_val_gray shape:', X_val_gray.shape)

X_train_gray shape: (40000, 32, 32, 1)
X_val_gray shape: (10000, 32, 32, 1)

from keras.callbacks import EarlyStopping

# define constants
batch_size = 128
epoch_max = 100
early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0)

def fit(model):
    hist = model.fit(X_train_gray, Y_train, \
                    batch_size=batch_size, \
                    nb_epoch=epoch_max, \
                    validation_data=(X_val_gray, Y_val), \
                    callbacks=[early_stop], \
                    shuffle=True, verbose=0)
    return hist

def evaluate(model, hist, plt_path):
    score = model.evaluate(X_test_gray, Y_test, verbose=0)
    print('Test loss: %.3f' % score[0])
    print('Test accuracy: %.3f' % score[1])
    plot_validation_history(hist, plt_path)

from keras.models import Sequential
from keras.layers import Dense, Flatten

baseline = Sequential()
# flatten our input into an 1-D array
baseline.add(Flatten(input_shape=(img_size, img_size, img_channels)))
# hidden layers
for i in range(8):
    baseline.add(Dense(512, activation='relu'))
# output layer
baseline.add(Dense(nb_classes, activation='softmax'))

# compile model
baseline.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# training & evaluatation
%time hist = fit(baseline)
evaluate(baseline, hist, 'output/fig-val-baseline.png')

CPU times: user 19.8 s, sys: 2.58 s, total: 22.4 s
Wall time: 22.4 s
Test loss: 1.790
Test accuracy: 0.404

baseline2 = Sequential()

# flatten our input into a single dimension array
baseline2.add(Flatten(input_shape=(img_size, img_size, img_channels)))
# hidden layers
baseline2.add(Dense(512, activation='relu'))
baseline2.add(Dense(256, activation='relu'))
baseline2.add(Dense(64, activation='relu'))
baseline2.add(Dense(32, activation='relu'))
# output layer
baseline2.add(Dense(nb_classes, activation='softmax'))

# compile model
baseline2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# training & evaluatation
%time hist = fit(baseline2)
evaluate(baseline2, hist, 'output/fig-val-baseline2.png')

CPU times: user 12.2 s, sys: 575 ms, total: 12.8 s
Wall time: 12.8 s
Test loss: 1.658
Test accuracy: 0.424

from keras.regularizers import l2

model_l2 = Sequential()
# flatten our input into a single dimension array
model_l2.add(Flatten(input_shape=(img_size, img_size, img_channels)))

# hidden layers
l2_alpha = 0.0005
for i in range(8):
    # penalize the L2-norm of the weight matrix 
    model_l2.add(Dense(512, activation='relu', W_regularizer=l2(l2_alpha)))
# output layer
model_l2.add(Dense(nb_classes, activation='softmax', W_regularizer=l2(l2_alpha)))

# compile model
model_l2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# training & evaluatation
%time hist = fit(model_l2)
evaluate(model_l2, hist, 'output/fig-val-model-l2.png')

CPU times: user 55.5 s, sys: 11.9 s, total: 1min 7s
Wall time: 1min 7s
Test loss: 1.945
Test accuracy: 0.296

from keras.constraints import maxnorm

model_c = Sequential()
# flatten our input into a single dimension array
model_c.add(Flatten(input_shape=(img_size, img_size, img_channels)))

# hidden layers
c_maxnorm = 0.7
for i in range(8):
    # constrain the weights incident to each hidden unit
    model_c.add(Dense(512, activation='relu', W_constraint=maxnorm(c_maxnorm)))
# output layer
model_c.add(Dense(nb_classes, activation='softmax', W_constraint=maxnorm(c_maxnorm)))

# compile model
model_c.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# training & evaluatation
%time hist = fit(model_c)
evaluate(model_c, hist, 'output/fig-val-model-c.png')

CPU times: user 39.9 s, sys: 5.38 s, total: 45.3 s
Wall time: 45.3 s
Test loss: 1.745
Test accuracy: 0.381

from keras.layers import Activation
from keras.layers.normalization import BatchNormalization

model_bn = Sequential()

# flatten our input into a single dimension array
model_bn.add(Flatten(input_shape=(img_size, img_size, img_channels)))

# hidden layers
for i in range(8):
    model_bn.add(Dense(512))
    # add BatchNormalization after summation sublayer and before activation sublayer
    model_bn.add(BatchNormalization(mode=1))
    model_bn.add(Activation('relu'))
# output layer
model_bn.add(Dense(nb_classes, activation='softmax', W_constraint=maxnorm(drop_maxnorm)))

# compile model
model_bn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# training & evaluatation
%time hist = fit(model_bn)
evaluate(model_bn, hist, 'output/fig-val-model-bn.png')

CPU times: user 45 s, sys: 1.8 s, total: 46.8 s
Wall time: 46.7 s
Test loss: 1.694
Test accuracy: 0.425

from keras.layers import Activation
from keras.layers.normalization import BatchNormalization
from keras.layers import Dropout

model_drop = Sequential()

# flatten our input into a single dimension array
model_drop.add(Flatten(input_shape=(img_size, img_size, img_channels)))

# hidden layers
drop_rate = 0.2
for i in range(8):
    model_drop.add(Dense(512))
    model_drop.add(BatchNormalization(mode=1))
    model_drop.add(Activation('relu'))
    # dropout neurons randomly
    model_drop.add(Dropout(drop_rate))
# output layer
model_drop.add(Dense(nb_classes, activation='softmax'))

# compile model
model_drop.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# training & evaluatation
%time hist = fit(model_drop)
evaluate(model_drop, hist, 'output/fig-val-model-drop.png')

CPU times: user 1min 30s, sys: 2.19 s, total: 1min 33s
Wall time: 1min 35s
Test loss: 1.618
Test accuracy: 0.447

from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

datagen = ImageDataGenerator(rotation_range=20, \
                             width_shift_range=0.1, \
                             height_shift_range=0.1, \
                             shear_range=0.1, \
                             zoom_range=0.2, \
                             horizontal_flip=True, \
                             fill_mode='nearest')

# visualize augmented points
plt.figure(figsize=(6, 6))
(X_batch, Y_batch) = datagen.flow(X_train_gray, Y_train, batch_size=9).next()
for i in range(9):
    plt.subplot(3, 3, (i + 1))
    plt.imshow(X_batch[i, :, :, 0], cmap=plt.get_cmap('gray'), interpolation='none')
plt.show()

128

from keras.layers import Activation
from keras.layers.normalization import BatchNormalization
from keras.layers import Dropout
from keras.preprocessing.image import ImageDataGenerator
import math

model_aug = Sequential()

# flatten our input into a single dimension array
model_aug.add(Flatten(input_shape=(img_size, img_size, img_channels)))

# hidden layers
for i in range(8):
    model_aug.add(Dense(512))
    model_aug.add(BatchNormalization(mode=1))
    model_aug.add(Activation('relu'))
# output layer
model_aug.add(Dense(nb_classes, activation='softmax'))

# compile model
model_aug.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# training
%time hist = model_aug.fit_generator( \
                     datagen.flow(X_train_gray, Y_train, batch_size=batch_size), \
                     samples_per_epoch=X_train_gray.shape[0], \
                     nb_epoch=epoch_max, \
                     validation_data=(X_val_gray, Y_val), \
                     callbacks=[early_stop], \
                     verbose=0)

# evaluation
evaluate(model_aug, hist, 'output/fig-val-model-aug.png')

/home/shwu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.
  warnings.warn('Epoch comprised more than '

CPU times: user 7min 43s, sys: 8.07 s, total: 7min 51s
Wall time: 7min 19s
Test loss: 1.504
Test accuracy: 0.469

model_aug2 = Sequential()

# flatten our input into a single dimension array
model_aug2.add(Flatten(input_shape=(img_size, img_size, img_channels)))

# hidden layers
for i in range(8):
    model_aug2.add(Dense(1024))
    model_aug2.add(BatchNormalization(mode=1))
    model_aug2.add(Activation('relu'))
# output layer
model_aug2.add(Dense(nb_classes, activation='softmax'))

# compile model
model_aug2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# training
%time hist = model_aug2.fit_generator( \
                     datagen.flow(X_train_gray, Y_train, batch_size=batch_size), \
                     samples_per_epoch=X_train_gray.shape[0], \
                     nb_epoch=epoch_max, \
                     validation_data=(X_val_gray, Y_val), \
                     callbacks=[early_stop], \
                     verbose=0)

# evaluation
evaluate(model_aug2, hist, 'output/fig-val-model-aug2.png')

/home/shwu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.
  warnings.warn('Epoch comprised more than '

CPU times: user 12min 48s, sys: 20.8 s, total: 13min 8s
Wall time: 11min 45s
Test loss: 1.432
Test accuracy: 0.502

from keras.layers.convolutional import Convolution2D, MaxPooling2D

model_cnn = Sequential()

# conolutional hidden layers
for i in range(6):
    model_cnn.add(Convolution2D(32, 3, 3, 
                        input_shape=(img_size, img_size, img_channels), 
                        border_mode='same', activation='relu'))
    if (i + 1) % 2 == 0:
        model_cnn.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))

print('Output shape of last concolution layers: {0}'.format(model_cnn.output_shape))
model_cnn.add(Flatten())

# fully connected hidden layers
for i in range(2):
    model_cnn.add(Dense(512))
    model_cnn.add(BatchNormalization(mode=1))
    model_cnn.add(Activation('relu'))

# output layer
model_cnn.add(Dense(nb_classes, activation='softmax'))

# compile model
model_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# training & evaluatation
%time hist = fit(model_cnn)
evaluate(model_cnn, hist, 'output/fig-val-model-cnn.png')

Output shape of last concolution layers: (None, 4, 4, 32)
CPU times: user 1min 53s, sys: 31.4 s, total: 2min 24s
Wall time: 2min 26s
Test loss: 1.037
Test accuracy: 0.698

print('baseline: {0} parameters'.format(baseline.count_params()))
print('model_bn: {0} parameters'.format(model_bn.count_params()))
print('model_cnn: {0} parameters'.format(model_cnn.count_params()))

baseline: 2368522 parameters
model_bn: 2384906 parameters
model_cnn: 581098 parameters

model_cnn2 = Sequential()

# convolutional hidden layers
for i in range(6):
    model_cnn2.add(Convolution2D(32, 3, 3, 
                        input_shape=(img_size, img_size, img_channels), 
                        border_mode='same', activation='relu'))
    if (i + 1) % 2 == 0:
        model_cnn2.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))

print('Output shape of last concolution layers: {0}'.format(model_cnn2.output_shape))
model_cnn2.add(Flatten())

# fully connected hidden layers
for i in range(2):
    model_cnn2.add(Dense(512))
    model_cnn2.add(BatchNormalization(mode=1))
    model_cnn2.add(Activation('relu'))

# output layer
model_cnn2.add(Dense(nb_classes, activation='softmax'))

# compile model
model_cnn2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# training
%time hist = model_cnn2.fit_generator( \
                     datagen.flow(X_train_gray, Y_train, batch_size=batch_size), \
                     samples_per_epoch=X_train_gray.shape[0], \
                     nb_epoch=epoch_max, \
                     validation_data=(X_val_gray, Y_val), \
                     callbacks=[early_stop], \
                     verbose=0)

# evaluation
evaluate(model_cnn2, hist, 'output/fig-val-model-cnn2.png')

Output shape of last concolution layers: (None, 4, 4, 32)
CPU times: user 10min 13s, sys: 1min 57s, total: 12min 11s
Wall time: 8min 38s
Test loss: 0.611
Test accuracy: 0.793

model_cnn3 = Sequential()

# convolutional hidden layers
drop_rate = 0.2
for i in range(6):
    model_cnn3.add(Convolution2D(64, 3, 3, 
                        input_shape=(img_size, img_size, img_channels), 
                        border_mode='same', activation='relu'))
    model_cnn3.add(Dropout(drop_rate))
    if (i + 1) % 2 == 0:
        model_cnn3.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))

print('Output shape of last concolution layers: {0}'.format(model_cnn3.output_shape))
model_cnn3.add(Flatten())

# fully connected hidden layers
for i in range(2):
    model_cnn3.add(Dense(1024))
    model_cnn3.add(BatchNormalization(mode=1))
    model_cnn3.add(Activation('relu'))
    model_cnn3.add(Dropout(drop_rate))

# output layer
model_cnn3.add(Dense(nb_classes, activation='softmax'))

# compile model
model_cnn3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# training
%time hist = model_cnn3.fit_generator( \
                     datagen.flow(X_train_gray, Y_train, batch_size=batch_size), \
                     samples_per_epoch=X_train_gray.shape[0], \
                     nb_epoch=epoch_max, \
                     validation_data=(X_val_gray, Y_val), \
                     callbacks=[early_stop], \
                     verbose=0)

# evaluation
evaluate(model_cnn3, hist, 'output/fig-val-model-cnn3.png')

Output shape of last concolution layers: (None, 4, 4, 64)
CPU times: user 19min 52s, sys: 4min 35s, total: 24min 27s
Wall time: 20min
Test loss: 0.526
Test accuracy: 0.820

print('baseline: {0} parameters'.format(baseline.count_params()))
print('model_cnn3: {0} parameters'.format(model_cnn3.count_params()))

baseline: 2368522 parameters
model_cnn3: 2302922 parameters
